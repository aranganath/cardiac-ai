{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (1.7.6)\n",
      "Requirement already satisfied: numpy in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from xgboost) (1.25.1)\n",
      "Requirement already satisfied: scipy in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from xgboost) (1.11.1)\n",
      "Requirement already satisfied: pandas in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (2.0.3)\n",
      "Requirement already satisfied: numpy>=1.20.3 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pandas) (1.25.1)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pandas) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pandas) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from python-dateutil>=2.8.2->pandas) (1.16.0)\n",
      "Requirement already satisfied: matplotlib in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (3.7.2)\n",
      "Requirement already satisfied: numpy>=1.20 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (1.25.1)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (0.11.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (4.41.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (3.0.9)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (23.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (10.0.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (1.1.0)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (2.8.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (1.4.4)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib) (5.12.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib) (3.15.0)\n",
      "Requirement already satisfied: six>=1.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib) (1.16.0)\n",
      "Requirement already satisfied: seaborn in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (0.12.2)\n",
      "Requirement already satisfied: matplotlib!=3.6.1,>=3.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from seaborn) (3.7.2)\n",
      "Requirement already satisfied: numpy!=1.24.0,>=1.17 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from seaborn) (1.25.1)\n",
      "Requirement already satisfied: pandas>=0.25 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from seaborn) (2.0.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (10.0.0)\n",
      "Requirement already satisfied: importlib-resources>=3.2.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (5.12.0)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (4.41.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.4.4)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (1.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (0.11.0)\n",
      "Requirement already satisfied: pyparsing<3.1,>=2.3.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (3.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (2.8.2)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from matplotlib!=3.6.1,>=3.1->seaborn) (23.0)\n",
      "Requirement already satisfied: zipp>=3.1.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from importlib-resources>=3.2.0->matplotlib!=3.6.1,>=3.1->seaborn) (3.15.0)\n",
      "Requirement already satisfied: tzdata>=2022.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pandas>=0.25->seaborn) (2023.3)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from pandas>=0.25->seaborn) (2023.3)\n",
      "Requirement already satisfied: six>=1.5 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from python-dateutil>=2.7->matplotlib!=3.6.1,>=3.1->seaborn) (1.16.0)\n",
      "Requirement already satisfied: scikit-learn in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (1.3.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from scikit-learn) (1.3.1)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from scikit-learn) (3.2.0)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from scikit-learn) (1.11.1)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from scikit-learn) (1.25.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install xgboost\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install seaborn\n",
    "!pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "PiuLQsQnpvwl",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import xgboost as xgb\n",
    "from xgboost import XGBClassifier\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "vdBkAKv3qCgU",
    "outputId": "dda3d978-f8c5-429f-8e3a-56000f1fbf75",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((87554, 188), (21892, 188))"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Import Dataset + Data Preprocessing\n",
    "df_mitbih_train = pd.read_csv(r\"C:\\Users\\calvi\\Documents\\Datasets\\ecg_dataset\\mitbih_train.csv\", header = None)\n",
    "df_mitbih_test = pd.read_csv(r\"C:\\Users\\calvi\\Documents\\Datasets\\ecg_dataset\\mitbih_test.csv\", header = None)\n",
    "\n",
    "df_mitbih_train.shape, df_mitbih_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "4-VAM-OUqFqD",
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = df_mitbih_train.drop(columns=[187])\n",
    "y_train = df_mitbih_train[187]\n",
    "X_test = df_mitbih_test.drop(columns=[187])\n",
    "y_test = df_mitbih_test[187]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9UDsJXOiqI82",
    "outputId": "094c9965-a252-4cbd-e3c2-c2e5c3cc4e86",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=0, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=-1, num_class=5, num_parallel_tree=None,\n",
      "              objective='multi:softmax', ...)\n"
     ]
    }
   ],
   "source": [
    "model = xgb.XGBClassifier(tree_method='gpu_hist', gpu_id=0, objective = 'multi:softmax', n_jobs = -1, num_class = 5, learning_rate = 0.1)\n",
    "model.fit(X_train, y_train)\n",
    "print(); print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w9MXxUfsqOJ4",
    "outputId": "46c02664-3b20-4955-a27a-8410786bca68",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      1.00      0.99     18118\n",
      "         1.0       0.94      0.61      0.74       556\n",
      "         2.0       0.97      0.89      0.92      1448\n",
      "         3.0       0.86      0.69      0.77       162\n",
      "         4.0       0.99      0.95      0.97      1608\n",
      "\n",
      "    accuracy                           0.97     21892\n",
      "   macro avg       0.95      0.83      0.88     21892\n",
      "weighted avg       0.97      0.97      0.97     21892\n",
      "\n"
     ]
    }
   ],
   "source": [
    "expected_y  = y_test\n",
    "predicted_y = model.predict(X_test)\n",
    "\n",
    "print(metrics.classification_report(expected_y, predicted_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "9LkdRp2KqStn",
    "outputId": "216e80b3-77fc-4dbf-984b-6d349b79998a",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 2 candidates, totalling 10 fits\n",
      "[CV 1/5] END n_estimators=3000;, score=(train=1.000, test=0.977) total time=  37.6s\n",
      "[CV 2/5] END n_estimators=3000;, score=(train=1.000, test=0.969) total time=  37.5s\n",
      "[CV 3/5] END n_estimators=3000;, score=(train=1.000, test=0.974) total time=  37.7s\n",
      "[CV 4/5] END n_estimators=3000;, score=(train=1.000, test=0.978) total time=  38.2s\n",
      "[CV 5/5] END n_estimators=3000;, score=(train=1.000, test=0.972) total time=  37.6s\n",
      "[CV 1/5] END n_estimators=3100;, score=(train=1.000, test=0.977) total time=  38.5s\n",
      "[CV 2/5] END n_estimators=3100;, score=(train=1.000, test=0.969) total time=  38.2s\n",
      "[CV 3/5] END n_estimators=3100;, score=(train=1.000, test=0.974) total time=  38.5s\n",
      "[CV 4/5] END n_estimators=3100;, score=(train=1.000, test=0.978) total time=  38.5s\n",
      "[CV 5/5] END n_estimators=3100;, score=(train=1.000, test=0.972) total time=  38.2s\n",
      "Best Parameters: {'n_estimators': 3000}\n",
      "Best Score: 0.974054530160821\n"
     ]
    }
   ],
   "source": [
    "n_estimators = range(3000, 3101, 100)\n",
    "param_grid = dict(n_estimators=n_estimators)\n",
    "\n",
    "grid_cv = GridSearchCV(model, param_grid, return_train_score = True, verbose = 3)\n",
    "_ = grid_cv.fit(X_test, y_test)\n",
    "\n",
    "print(f'Best Parameters:', grid_cv.best_params_)\n",
    "print(f'Best Score:', grid_cv.best_score_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: hyperopt in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (0.2.7)\n",
      "Requirement already satisfied: scipy in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from hyperopt) (1.11.1)\n",
      "Requirement already satisfied: future in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from hyperopt) (0.18.3)\n",
      "Requirement already satisfied: py4j in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from hyperopt) (0.10.9.7)\n",
      "Requirement already satisfied: six in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from hyperopt) (1.16.0)\n",
      "Requirement already satisfied: cloudpickle in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from hyperopt) (2.2.1)\n",
      "Requirement already satisfied: networkx>=2.2 in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from hyperopt) (3.1)\n",
      "Requirement already satisfied: tqdm in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from hyperopt) (4.65.0)\n",
      "Requirement already satisfied: numpy in /home/studio-lab-user/.conda/envs/default/lib/python3.9/site-packages (from hyperopt) (1.25.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install hyperopt\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from hyperopt import STATUS_OK, Trials, fmin, hp, tpe\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "space={'max_depth': hp.quniform(\"max_depth\", 3, 18, 1),\n",
    "        'gamma': hp.uniform ('gamma', 1,9),\n",
    "        'reg_alpha' : hp.quniform('reg_alpha', 40,180,1),\n",
    "        'reg_lambda' : hp.uniform('reg_lambda', 0,1),\n",
    "        'colsample_bytree' : hp.uniform('colsample_bytree', 0.5,1),\n",
    "        'min_child_weight' : hp.quniform('min_child_weight', 0, 10, 1),\n",
    "        'n_estimators': 3000,\n",
    "        'seed': 0\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf = xgb.XGBClassifier(tree_method='gpu_hist', gpu_id=0, objective = 'multi:softmax', n_jobs = -1, num_class = 5, learning_rate = 0.3)\n",
    "def objective(space):\n",
    "    clf=xgb.XGBClassifier(\n",
    "                    n_estimators = 3000, max_depth = int(space['max_depth']), gamma = space['gamma'],\n",
    "                    reg_alpha = int(space['reg_alpha']),min_child_weight=int(space['min_child_weight']),\n",
    "                    colsample_bytree=int(space['colsample_bytree']))\n",
    "    \n",
    "    evaluation = [( X_train, y_train), ( X_test, y_test)]\n",
    "    \n",
    "    clf.fit(X_train, y_train,\n",
    "            eval_set=evaluation, eval_metric=\"auc\",\n",
    "            early_stopping_rounds=10,verbose=False)\n",
    "    \n",
    "\n",
    "    pred = clf.predict(X_test)\n",
    "    accuracy = accuracy_score(y_test, pred>0.5)\n",
    "    print (\"SCORE:\", accuracy)\n",
    "    return {'loss': -accuracy, 'status': STATUS_OK }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=None, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=None, gpu_id=0, grow_policy=None, importance_type=None,\n",
      "              interaction_constraints=None, learning_rate=0.3, max_bin=None,\n",
      "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
      "              max_delta_step=None, max_depth=None, max_leaves=None,\n",
      "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
      "              n_estimators=100, n_jobs=-1, num_class=5, num_parallel_tree=None,\n",
      "              objective='multi:softmax', ...)\n"
     ]
    }
   ],
   "source": [
    "print(); print(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SCORE:                                                 \n",
      "0.8332724282843048                                     \n",
      "SCORE:                                                                            \n",
      "0.8336378585784762                                                                \n",
      "SCORE:                                                                            \n",
      "0.8338662525123333                                                                \n",
      "SCORE:                                                                              \n",
      "0.8336378585784762                                                                  \n",
      "SCORE:                                                                              \n",
      "0.8338662525123333                                                                  \n",
      "SCORE:                                                                              \n",
      "0.8329983555636762                                                                  \n",
      "SCORE:                                                                              \n",
      "0.8340032888726475                                                                \n",
      "SCORE:                                                                            \n",
      "0.8336835373652476                                                                \n",
      "SCORE:                                                                            \n",
      "0.833729216152019                                                                 \n",
      "SCORE:                                                                            \n",
      "0.8335465010049333                                                                \n",
      "SCORE:                                                                             \n",
      "0.833729216152019                                                                  \n",
      "SCORE:                                                                             \n",
      "0.8329069979901333                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8341860040197332                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8319477434679335                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8339119312991047                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8335008222181619                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8343230403800475                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8334094646446191                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8338205737255618                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8336378585784762                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8342316828065046                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8345057555271332                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8340489676594189                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8344143979535904                                                                 \n",
      "SCORE:                                                                               \n",
      "0.8342316828065046                                                                   \n",
      "SCORE:                                                                               \n",
      "0.8344143979535904                                                                   \n",
      "SCORE:                                                                               \n",
      "0.8335921797917047                                                                   \n",
      "SCORE:                                                                               \n",
      "0.8341403252329618                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8334551434313905                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8346884706742189                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8339576100858761                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8340489676594189                                                                 \n",
      "SCORE:                                                                             \n",
      "0.834368719166819                                                                  \n",
      "SCORE:                                                                             \n",
      "0.8341403252329618                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8321304586150192                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8338662525123333                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8340032888726475                                                                 \n",
      "SCORE:                                                                             \n",
      "0.834277361593276                                                                  \n",
      "SCORE:                                                                             \n",
      "0.833729216152019                                                                  \n",
      "SCORE:                                                                             \n",
      "0.8334551434313905                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8338662525123333                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8339576100858761                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8341860040197332                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8339576100858761                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8341403252329618                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8340946464461904                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8329526767769048                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8341860040197332                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8346884706742189                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8341860040197332                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8341860040197332                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8338205737255618                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8329526767769048                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8340032888726475                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8335465010049333                                                                 \n",
      "SCORE:                                                                             \n",
      "0.834277361593276                                                                  \n",
      "SCORE:                                                                             \n",
      "0.8341860040197332                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8339576100858761                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8329069979901333                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8339119312991047                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8341403252329618                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8344600767403618                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8340032888726475                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8343230403800475                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8339119312991047                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8339576100858761                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8344143979535904                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8341403252329618                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8338662525123333                                                                 \n",
      "SCORE:                                                                             \n",
      "0.834277361593276                                                                  \n",
      "SCORE:                                                                             \n",
      "0.8340946464461904                                                                 \n",
      "SCORE:                                                                             \n",
      "0.834368719166819                                                                  \n",
      "SCORE:                                                                             \n",
      "0.8340489676594189                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8343230403800475                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8338205737255618                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8342316828065046                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8341403252329618                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8340032888726475                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8343230403800475                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8341860040197332                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8342316828065046                                                                 \n",
      "SCORE:                                                                             \n",
      "0.8337748949387904                                                                   \n",
      "SCORE:                                                                               \n",
      "0.8342316828065046                                                                   \n",
      "SCORE:                                                                               \n",
      "0.8337748949387904                                                                   \n",
      "SCORE:                                                                               \n",
      "0.8326786040562763                                                                   \n",
      "SCORE:                                                                               \n",
      "0.8339119312991047                                                                   \n",
      "SCORE:                                                                               \n",
      "0.8333181070710762                                                                   \n",
      "SCORE:                                                                               \n",
      "0.8335921797917047                                                                   \n",
      "SCORE:                                                                               \n",
      "0.834368719166819                                                                    \n",
      "SCORE:                                                                               \n",
      "0.8340032888726475                                                                   \n",
      "SCORE:                                                                               \n",
      "0.8339119312991047                                                                   \n",
      "SCORE:                                                                               \n",
      "0.8342316828065046                                                                   \n",
      "SCORE:                                                                               \n",
      "0.8335465010049333                                                                   \n",
      "SCORE:                                                                               \n",
      "0.8342316828065046                                                                   \n",
      "SCORE:                                                                               \n",
      "0.8342316828065046                                                                   \n",
      "SCORE:                                                                               \n",
      "0.8345057555271332                                                                   \n",
      "SCORE:                                                                               \n",
      "0.8341403252329618                                                                   \n",
      "SCORE:                                                                               \n",
      "0.8341860040197332                                                                   \n",
      "SCORE:                                                                               \n",
      "0.8342316828065046                                                                   \n",
      "SCORE:                                                                               \n",
      "0.8341860040197332                                                                   \n",
      "100%|██████████| 100/100 [1:14:10<00:00, 44.51s/trial, best loss: -0.8346884706742189]\n"
     ]
    }
   ],
   "source": [
    "trials = Trials()\n",
    "\n",
    "best_hyperparams = fmin(fn = objective,\n",
    "                        space = space,\n",
    "                        algo = tpe.suggest,\n",
    "                        max_evals = 100,\n",
    "                        trials = trials)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The best hyperparameters are :  \n",
      "\n",
      "{'colsample_bytree': 0.934397209208678, 'gamma': 2.056550422157872, 'max_depth': 6.0, 'min_child_weight': 6.0, 'reg_alpha': 41.0, 'reg_lambda': 0.251398330291195}\n"
     ]
    }
   ],
   "source": [
    "print(\"The best hyperparameters are : \",\"\\n\")\n",
    "print(best_hyperparams)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
      "              colsample_bylevel=None, colsample_bynode=None,\n",
      "              colsample_bytree=0.934397209208678, early_stopping_rounds=None,\n",
      "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
      "              gamma=2.056550422157872, gpu_id=0, grow_policy=None,\n",
      "              importance_type=None, interaction_constraints=None,\n",
      "              learning_rate=0.1, max_bin=None, max_cat_threshold=None,\n",
      "              max_cat_to_onehot=None, max_delta_step=None, max_depth=6,\n",
      "              max_leaves=None, min_child_weight=6, missing=nan,\n",
      "              monotone_constraints=None, n_estimators=3000, n_jobs=-1,\n",
      "              num_class=5, num_parallel_tree=None, objective='multi:softmax', ...)\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         0.0       0.97      1.00      0.98     18118\n",
      "         1.0       0.96      0.56      0.71       556\n",
      "         2.0       0.95      0.85      0.90      1448\n",
      "         3.0       0.80      0.42      0.55       162\n",
      "         4.0       0.99      0.93      0.96      1608\n",
      "\n",
      "    accuracy                           0.97     21892\n",
      "   macro avg       0.93      0.75      0.82     21892\n",
      "weighted avg       0.97      0.97      0.96     21892\n",
      "\n"
     ]
    }
   ],
   "source": [
    "last_model = xgb.XGBClassifier(\n",
    "                    n_estimators = 3000,\n",
    "                    learning_rate = 0.1,\n",
    "                    max_depth = 6,\n",
    "                    gamma = 2.056550422157872,\n",
    "                    reg_alpha = 41,\n",
    "                    min_child_weight= 6,\n",
    "                    colsample_bytree= 0.934397209208678,\n",
    "                    reg_lambda= 0.251398330291195,\n",
    "                    tree_method='gpu_hist',\n",
    "                    gpu_id=0,\n",
    "                    objective = 'multi:softmax',\n",
    "                    n_jobs = -1,\n",
    "                    num_class = 5\n",
    ")\n",
    "\n",
    "last_model.fit(X_train, y_train)\n",
    "print(); print(last_model)\n",
    "expected_y  = y_test\n",
    "predicted_y = last_model.predict(X_test)\n",
    "print(metrics.classification_report(expected_y, predicted_y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
