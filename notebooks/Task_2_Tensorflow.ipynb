{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "id": "MArdzd64vlGE"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn import metrics\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.metrics import classification_report\n",
        "import tensorflow as tf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dq6ddSyIvu0P",
        "outputId": "681d8749-5577-47ac-cfdc-f9e2ad62e819"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "((87554, 188), (21892, 188))"
            ]
          },
          "execution_count": 13,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "df_mitbih_train = pd.read_csv(r\"../Datasets/ecg_dataset/mitbih_train.csv\", header=None)\n",
        "df_mitbih_test = pd.read_csv(r\"../Datasets/ecg_dataset/mitbih_test.csv\", header=None)\n",
        "\n",
        "df_mitbih_train.shape, df_mitbih_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "7vP0pPCRvxDX"
      },
      "outputs": [],
      "source": [
        "X_train = df_mitbih_train.drop(columns=[187])\n",
        "y_train = df_mitbih_train[187]\n",
        "X_test = df_mitbih_test.drop(columns=[187])\n",
        "y_test = df_mitbih_test[187]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "kzquU9mkvzfT"
      },
      "outputs": [],
      "source": [
        "label_encoder = LabelEncoder()\n",
        "y_train_encoded = label_encoder.fit_transform(y_train)\n",
        "y_test_encoded = label_encoder.transform(y_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4_5WDmTpv1yD",
        "outputId": "4a9c6a58-9511-4a02-81b8-0001c21ed2a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_1 (Flatten)         (None, 187)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 50)                9400      \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 50)                2550      \n",
            "                                                                 \n",
            " dense_5 (Dense)             (None, 5)                 255       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 12,205\n",
            "Trainable params: 12,205\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "# Example usage:\n",
        "# Replace 'num_features' and 'num_classes' with appropriate values for your dataset\n",
        "input_shape = 187\n",
        "num_features = 187\n",
        "num_classes = 5\n",
        "\n",
        "def create_multiclass_model(input_shape, num_classes):\n",
        "    \"\"\"\n",
        "    Create a multiclass classification model using TensorFlow.\n",
        "\n",
        "    Parameters:\n",
        "    input_shape (tuple): The shape of input data. For example, (num_features,).\n",
        "    num_classes (int): The number of classes for classification.\n",
        "\n",
        "    Returns:\n",
        "    model (tf.keras.Model): The created TensorFlow model.\n",
        "    \"\"\"\n",
        "\n",
        "    # Define the model architecture\n",
        "    model = tf.keras.Sequential([\n",
        "        tf.keras.layers.Input(shape=input_shape),\n",
        "        tf.keras.layers.Flatten(),\n",
        "        tf.keras.layers.Dense(50, activation='relu'),\n",
        "        tf.keras.layers.Dense(50, activation='relu'),\n",
        "        tf.keras.layers.Dense(num_classes, activation='softmax')\n",
        "    ])\n",
        "\n",
        "    # Compile the model\n",
        "    model.compile(\n",
        "        loss=tf.keras.losses.SparseCategoricalCrossentropy(),\n",
        "        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "        metrics=['accuracy']\n",
        "    )\n",
        "\n",
        "    return model\n",
        "\n",
        "model = create_multiclass_model((num_features,), num_classes)\n",
        "model.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 451
        },
        "id": "lrxN0ibzv5jr",
        "outputId": "d0e67a7c-ab89-45ed-8703-55859a5f93ec"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.1902 - accuracy: 0.9496 - val_loss: 11.1679 - val_accuracy: 0.1481\n",
            "Epoch 2/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.1136 - accuracy: 0.9704 - val_loss: 14.9430 - val_accuracy: 0.1535\n",
            "Epoch 3/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0967 - accuracy: 0.9745 - val_loss: 16.7492 - val_accuracy: 0.1602\n",
            "Epoch 4/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0860 - accuracy: 0.9767 - val_loss: 17.8060 - val_accuracy: 0.1592\n",
            "Epoch 5/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0795 - accuracy: 0.9784 - val_loss: 17.7086 - val_accuracy: 0.1731\n",
            "Epoch 6/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0746 - accuracy: 0.9792 - val_loss: 19.9176 - val_accuracy: 0.1633\n",
            "Epoch 7/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0694 - accuracy: 0.9807 - val_loss: 18.1996 - val_accuracy: 0.1786\n",
            "Epoch 8/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0654 - accuracy: 0.9811 - val_loss: 23.0569 - val_accuracy: 0.1736\n",
            "Epoch 9/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0628 - accuracy: 0.9822 - val_loss: 23.6175 - val_accuracy: 0.1593\n",
            "Epoch 10/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0599 - accuracy: 0.9822 - val_loss: 25.7866 - val_accuracy: 0.1664\n",
            "Epoch 11/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0588 - accuracy: 0.9831 - val_loss: 26.1862 - val_accuracy: 0.1728\n",
            "Epoch 12/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0552 - accuracy: 0.9841 - val_loss: 27.7494 - val_accuracy: 0.1760\n",
            "Epoch 13/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0545 - accuracy: 0.9837 - val_loss: 29.5937 - val_accuracy: 0.1705\n",
            "Epoch 14/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0517 - accuracy: 0.9848 - val_loss: 31.4606 - val_accuracy: 0.1730\n",
            "Epoch 15/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0510 - accuracy: 0.9849 - val_loss: 31.6471 - val_accuracy: 0.1751\n",
            "Epoch 16/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0495 - accuracy: 0.9857 - val_loss: 34.2519 - val_accuracy: 0.1747\n",
            "Epoch 17/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0488 - accuracy: 0.9856 - val_loss: 35.6347 - val_accuracy: 0.1759\n",
            "Epoch 18/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0476 - accuracy: 0.9859 - val_loss: 34.7698 - val_accuracy: 0.1681\n",
            "Epoch 19/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0463 - accuracy: 0.9859 - val_loss: 37.8250 - val_accuracy: 0.1705\n",
            "Epoch 20/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0448 - accuracy: 0.9866 - val_loss: 36.2229 - val_accuracy: 0.1733\n",
            "Epoch 21/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0437 - accuracy: 0.9870 - val_loss: 37.0201 - val_accuracy: 0.1744\n",
            "Epoch 22/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0421 - accuracy: 0.9872 - val_loss: 42.6487 - val_accuracy: 0.1658\n",
            "Epoch 23/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0416 - accuracy: 0.9874 - val_loss: 40.8636 - val_accuracy: 0.1765\n",
            "Epoch 24/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0413 - accuracy: 0.9875 - val_loss: 38.6969 - val_accuracy: 0.1710\n",
            "Epoch 25/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0406 - accuracy: 0.9879 - val_loss: 39.9571 - val_accuracy: 0.1761\n",
            "Epoch 26/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0389 - accuracy: 0.9882 - val_loss: 37.8610 - val_accuracy: 0.1760\n",
            "Epoch 27/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0381 - accuracy: 0.9883 - val_loss: 41.7192 - val_accuracy: 0.1750\n",
            "Epoch 28/100\n",
            "1576/1576 [==============================] - 3s 2ms/step - loss: 0.0374 - accuracy: 0.9887 - val_loss: 41.6474 - val_accuracy: 0.1759\n",
            "Epoch 29/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0370 - accuracy: 0.9885 - val_loss: 44.6937 - val_accuracy: 0.1757\n",
            "Epoch 30/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0361 - accuracy: 0.9888 - val_loss: 42.4935 - val_accuracy: 0.1765\n",
            "Epoch 31/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0360 - accuracy: 0.9889 - val_loss: 43.5762 - val_accuracy: 0.1758\n",
            "Epoch 32/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0353 - accuracy: 0.9890 - val_loss: 39.7768 - val_accuracy: 0.1780\n",
            "Epoch 33/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0341 - accuracy: 0.9894 - val_loss: 42.8309 - val_accuracy: 0.1755\n",
            "Epoch 34/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0338 - accuracy: 0.9896 - val_loss: 43.0347 - val_accuracy: 0.1771\n",
            "Epoch 35/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0331 - accuracy: 0.9894 - val_loss: 43.3490 - val_accuracy: 0.1787\n",
            "Epoch 36/100\n",
            "1576/1576 [==============================] - 3s 2ms/step - loss: 0.0322 - accuracy: 0.9899 - val_loss: 43.0432 - val_accuracy: 0.1788\n",
            "Epoch 37/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0313 - accuracy: 0.9903 - val_loss: 43.2395 - val_accuracy: 0.1749\n",
            "Epoch 38/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0317 - accuracy: 0.9901 - val_loss: 44.6497 - val_accuracy: 0.1758\n",
            "Epoch 39/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0303 - accuracy: 0.9904 - val_loss: 42.3760 - val_accuracy: 0.1786\n",
            "Epoch 40/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0298 - accuracy: 0.9907 - val_loss: 48.5820 - val_accuracy: 0.1743\n",
            "Epoch 41/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0298 - accuracy: 0.9908 - val_loss: 43.9751 - val_accuracy: 0.1755\n",
            "Epoch 42/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0294 - accuracy: 0.9906 - val_loss: 44.1705 - val_accuracy: 0.1782\n",
            "Epoch 43/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0284 - accuracy: 0.9909 - val_loss: 46.6239 - val_accuracy: 0.1778\n",
            "Epoch 44/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0287 - accuracy: 0.9907 - val_loss: 45.7232 - val_accuracy: 0.1796\n",
            "Epoch 45/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0278 - accuracy: 0.9913 - val_loss: 49.8300 - val_accuracy: 0.1735\n",
            "Epoch 46/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0279 - accuracy: 0.9910 - val_loss: 44.0171 - val_accuracy: 0.1799\n",
            "Epoch 47/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0263 - accuracy: 0.9918 - val_loss: 47.9233 - val_accuracy: 0.1714\n",
            "Epoch 48/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0264 - accuracy: 0.9915 - val_loss: 50.9455 - val_accuracy: 0.1758\n",
            "Epoch 49/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0262 - accuracy: 0.9915 - val_loss: 47.9560 - val_accuracy: 0.1800\n",
            "Epoch 50/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0262 - accuracy: 0.9917 - val_loss: 51.0666 - val_accuracy: 0.1757\n",
            "Epoch 51/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0252 - accuracy: 0.9919 - val_loss: 50.1035 - val_accuracy: 0.1782\n",
            "Epoch 52/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0248 - accuracy: 0.9918 - val_loss: 47.8516 - val_accuracy: 0.1780\n",
            "Epoch 53/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0246 - accuracy: 0.9920 - val_loss: 49.7992 - val_accuracy: 0.1751\n",
            "Epoch 54/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0239 - accuracy: 0.9921 - val_loss: 48.2662 - val_accuracy: 0.1757\n",
            "Epoch 55/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0234 - accuracy: 0.9926 - val_loss: 51.1381 - val_accuracy: 0.1780\n",
            "Epoch 56/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0241 - accuracy: 0.9920 - val_loss: 53.4675 - val_accuracy: 0.1796\n",
            "Epoch 57/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0220 - accuracy: 0.9927 - val_loss: 52.2691 - val_accuracy: 0.1730\n",
            "Epoch 58/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0229 - accuracy: 0.9923 - val_loss: 51.0280 - val_accuracy: 0.1770\n",
            "Epoch 59/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0230 - accuracy: 0.9925 - val_loss: 52.1279 - val_accuracy: 0.1769\n",
            "Epoch 60/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0224 - accuracy: 0.9925 - val_loss: 52.2630 - val_accuracy: 0.1782\n",
            "Epoch 61/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0216 - accuracy: 0.9928 - val_loss: 53.4282 - val_accuracy: 0.1792\n",
            "Epoch 62/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0213 - accuracy: 0.9929 - val_loss: 53.4109 - val_accuracy: 0.1757\n",
            "Epoch 63/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0216 - accuracy: 0.9931 - val_loss: 56.7892 - val_accuracy: 0.1699\n",
            "Epoch 64/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0203 - accuracy: 0.9932 - val_loss: 55.2151 - val_accuracy: 0.1791\n",
            "Epoch 65/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0208 - accuracy: 0.9933 - val_loss: 54.9142 - val_accuracy: 0.1794\n",
            "Epoch 66/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0204 - accuracy: 0.9932 - val_loss: 55.2947 - val_accuracy: 0.1783\n",
            "Epoch 67/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0200 - accuracy: 0.9934 - val_loss: 57.2497 - val_accuracy: 0.1815\n",
            "Epoch 68/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0200 - accuracy: 0.9935 - val_loss: 53.7027 - val_accuracy: 0.1744\n",
            "Epoch 69/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0195 - accuracy: 0.9934 - val_loss: 61.2834 - val_accuracy: 0.1792\n",
            "Epoch 70/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0188 - accuracy: 0.9937 - val_loss: 54.2561 - val_accuracy: 0.1811\n",
            "Epoch 71/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0194 - accuracy: 0.9935 - val_loss: 63.3773 - val_accuracy: 0.1715\n",
            "Epoch 72/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0186 - accuracy: 0.9937 - val_loss: 59.4215 - val_accuracy: 0.1719\n",
            "Epoch 73/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0195 - accuracy: 0.9935 - val_loss: 57.2664 - val_accuracy: 0.1767\n",
            "Epoch 74/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0199 - accuracy: 0.9932 - val_loss: 56.6106 - val_accuracy: 0.1758\n",
            "Epoch 75/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0172 - accuracy: 0.9941 - val_loss: 59.7792 - val_accuracy: 0.1802\n",
            "Epoch 76/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0174 - accuracy: 0.9941 - val_loss: 63.1136 - val_accuracy: 0.1751\n",
            "Epoch 77/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0178 - accuracy: 0.9936 - val_loss: 61.8289 - val_accuracy: 0.1752\n",
            "Epoch 78/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0175 - accuracy: 0.9940 - val_loss: 61.5936 - val_accuracy: 0.1766\n",
            "Epoch 79/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0168 - accuracy: 0.9943 - val_loss: 57.9616 - val_accuracy: 0.1780\n",
            "Epoch 80/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0174 - accuracy: 0.9939 - val_loss: 62.5909 - val_accuracy: 0.1763\n",
            "Epoch 81/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0153 - accuracy: 0.9946 - val_loss: 60.7889 - val_accuracy: 0.1776\n",
            "Epoch 82/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0162 - accuracy: 0.9944 - val_loss: 64.1323 - val_accuracy: 0.1776\n",
            "Epoch 83/100\n",
            "1576/1576 [==============================] - 2s 2ms/step - loss: 0.0170 - accuracy: 0.9943 - val_loss: 60.7917 - val_accuracy: 0.1780\n",
            "Epoch 84/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0163 - accuracy: 0.9945 - val_loss: 62.3362 - val_accuracy: 0.1759\n",
            "Epoch 85/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0166 - accuracy: 0.9941 - val_loss: 57.4708 - val_accuracy: 0.1777\n",
            "Epoch 86/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0153 - accuracy: 0.9946 - val_loss: 61.0727 - val_accuracy: 0.1747\n",
            "Epoch 87/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0156 - accuracy: 0.9944 - val_loss: 63.0756 - val_accuracy: 0.1754\n",
            "Epoch 88/100\n",
            "1576/1576 [==============================] - 3s 2ms/step - loss: 0.0158 - accuracy: 0.9946 - val_loss: 63.6184 - val_accuracy: 0.1790\n",
            "Epoch 89/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0145 - accuracy: 0.9951 - val_loss: 65.0431 - val_accuracy: 0.1768\n",
            "Epoch 90/100\n",
            "1576/1576 [==============================] - 3s 2ms/step - loss: 0.0147 - accuracy: 0.9950 - val_loss: 63.3720 - val_accuracy: 0.1791\n",
            "Epoch 91/100\n",
            "1576/1576 [==============================] - 3s 2ms/step - loss: 0.0158 - accuracy: 0.9944 - val_loss: 66.2829 - val_accuracy: 0.1787\n",
            "Epoch 92/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0147 - accuracy: 0.9949 - val_loss: 62.4328 - val_accuracy: 0.1752\n",
            "Epoch 93/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0142 - accuracy: 0.9949 - val_loss: 64.2350 - val_accuracy: 0.1757\n",
            "Epoch 94/100\n",
            "1576/1576 [==============================] - 3s 2ms/step - loss: 0.0141 - accuracy: 0.9950 - val_loss: 69.1023 - val_accuracy: 0.1758\n",
            "Epoch 95/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0156 - accuracy: 0.9948 - val_loss: 64.0456 - val_accuracy: 0.1790\n",
            "Epoch 96/100\n",
            "1576/1576 [==============================] - 2s 2ms/step - loss: 0.0151 - accuracy: 0.9946 - val_loss: 67.3199 - val_accuracy: 0.1755\n",
            "Epoch 97/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0130 - accuracy: 0.9956 - val_loss: 69.1703 - val_accuracy: 0.1723\n",
            "Epoch 98/100\n",
            "1576/1576 [==============================] - 2s 1ms/step - loss: 0.0148 - accuracy: 0.9946 - val_loss: 68.9321 - val_accuracy: 0.1775\n",
            "Epoch 99/100\n",
            "1576/1576 [==============================] - 2s 2ms/step - loss: 0.0141 - accuracy: 0.9953 - val_loss: 66.6944 - val_accuracy: 0.1778\n",
            "Epoch 100/100\n",
            "1576/1576 [==============================] - 2s 2ms/step - loss: 0.0137 - accuracy: 0.9954 - val_loss: 67.7757 - val_accuracy: 0.1755\n",
            "685/685 [==============================] - 1s 1ms/step - loss: 7.0399 - accuracy: 0.9028\n",
            "Test accuracy: 0.9027955532073975\n"
          ]
        }
      ],
      "source": [
        "epochs = 100\n",
        "batch_size = 50\n",
        "\n",
        "model.fit(X_train, y_train_encoded, epochs=epochs, batch_size=batch_size, validation_split=0.1)\n",
        "\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test)\n",
        "print(f\"Test accuracy: {test_accuracy}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p-itx6GXv6I5",
        "outputId": "0b22fd5c-3017-409b-bcd9-821f4fa61506"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "685/685 [==============================] - 1s 1ms/step\n",
            "Classification Report:\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "         0.0       0.91      0.99      0.95     18118\n",
            "         1.0       0.77      0.74      0.76       556\n",
            "         2.0       0.82      0.93      0.87      1448\n",
            "         3.0       0.00      0.00      0.00       162\n",
            "         4.0       0.00      0.00      0.00      1608\n",
            "\n",
            "    accuracy                           0.90     21892\n",
            "   macro avg       0.50      0.53      0.52     21892\n",
            "weighted avg       0.83      0.90      0.86     21892\n",
            "\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "c:\\Users\\calvi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\calvi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n",
            "c:\\Users\\calvi\\anaconda3\\lib\\site-packages\\sklearn\\metrics\\_classification.py:1318: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, msg_start, len(result))\n"
          ]
        }
      ],
      "source": [
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = np.argmax(y_pred, axis= 1)\n",
        "\n",
        "print(\"Classification Report:\")\n",
        "print(classification_report(y_test, y_pred_classes))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RhnEOdaKucXy"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "TPU",
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
